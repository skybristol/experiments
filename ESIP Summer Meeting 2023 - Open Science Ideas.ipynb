{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the opening plenary at the ESIP Summer Meeting 2023, one of our exercises was looking at the different barriers to open science and coming up with some ideas via a sli.do poll on the big things we should do about it. The list was pretty huge and overwhelming, so I thought I'd throw it at an LLM with a prompt to give us a synthesis of essentially the most repeated (not counting popularity via up-voting) ideas. I use Llama Index here with the davinci 3 model from OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from llama_index import SimpleDirectoryReader, ListIndex, LLMPredictor, ServiceContext\n",
    "from langchain import OpenAI\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need an OPENAI key to run the call to the model; this could be improved to operate on another framework but this is quick and dirty\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    os.environ['OPENAI_API_KEY'] = getpass.getpass(prompt=\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TERM_STR = (\n",
    "    \"Use the lines in the provided documents that do not start with either 'Anonymous' or a number \"\n",
    "    \"to provide a synthesis of common ideas between the lines. \"\n",
    "    \"Structure your response as a list of the top 5 ideas summarized from the text. \"\n",
    "    \"Based on that set of synthesized ideas, show me a secondary list of 5 outliers, \"\n",
    "    \"prioritizing those lines with the greatest length of text.\"\n",
    ")\n",
    "\n",
    "term_extract_str = st.text_area(\"The query to extract terms and definitions with.\", value=DEFAULT_TERM_STR)\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0, \n",
    "    model_name=\"text-davinci-003\", \n",
    "    max_tokens=1024\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the documents here, I just used the expedient of a copy/paste from sli.do into a text document that I read in here. I include a filter in the prompt to only focus on the lines I care about - the poll responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('./data/open_science_poll').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the context\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=LLMPredictor(llm=llm), chunk_size=1024)\n",
    "index = ListIndex.from_documents(documents, service_context=service_context)\n",
    "query_engine = index.as_query_engine(response_mode=\"tree_summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the prompt\n",
    "sum_synth = str(query_engine.query(term_extract_str))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results aren't bad and show some interesting dynamics from the discussion. The synthesis ideas come across as pretty simplistic, but that's maybe what we would expect at this level - lots of basically the same ideas written out quickly without a lot of depth. I also find a look at the outliers to be kind of interesting. Really, we should have this kind of capacity immediately available behind Sli.do or any of these kinds of tools - use AI to summarize and synthesize what a big group of HI comes up with. It would also be interesting to incorporate vote counts into the mix here, looking at what adding that dimension does to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Top 5 Ideas:',\n",
       " '1. Increase access to data, tools, and resources for all.',\n",
       " '2. Improve communication and understanding between different categories of science.',\n",
       " '3. Provide training and empowerment opportunities for underrepresented and excluded backgrounds.',\n",
       " '4. Reduce jargon and make language more succinct and understood.',\n",
       " '5. Create community standards within disciplines.',\n",
       " '',\n",
       " 'Outliers:',\n",
       " '1. Demonstrate how an open science researcher can sustainably foster competitive, productive leading-edge research while still being regarded as an expert in their field throughout their career.',\n",
       " '2. Equity (not the same as equal) in access to build knowledge and skills and access to tools must be a baseline standard.',\n",
       " '3. Do wider outreach outside the science community â€” bring science to schools, libraries, etc. Make data accessible in ways a non-scientist can understand and appreciate, especially younger people who might pursue it in the future.',\n",
       " '4. Create interfaces, systems, and repository structures that lower the learning curve for contributing to open science.',\n",
       " '5. FIRST understand the key differences and CONCERNS among all minority groups involved. Reimagine open and productive science. Create a commercial open-source software company that offers geoprocessing infrastructure online with research advocates to support. People are free to self host or pay for the infrastructure service.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_synth.split(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geokb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
