{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracted PDF Annotation via Zotero.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1Ig6+HTr8tbKRt8lOkHgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skybristol/experiments/blob/dev/Extracted_PDF_Annotation_via_Zotero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtzwSnLRFKAJ"
      },
      "source": [
        "I'm experimenting here with a process to turn annotations created within PDF files stored as part of a Zotero library into metadata contents and structured annotations for the bibliographic record. This is essentially for cases where there is no good citation metadata already in existence somewhere on the web (e.g., for certain types of government reports) and we need to extract that content from within PDFs. It's also for cases where built-in structured PDF metadata is no good, which is the case for anything other than professionally built PDFs (e.g., just exporting a PDF from your word processor does not build a good PDF). This technique also holds promise for setting up training data for building various kinds of entity recognition models to auto-extract particular concepts from full texts processed with NLP.\n",
        "\n",
        "I used the ZotFile plugins for Zotero, inspired by [this video](https://www.youtube.com/watch?v=_Fjhad-Z61o&t=1251s). In Zotero, the process includes storing the PDF file as an attachment so that Zotero is \"managing\" it, annotating the file using some type of PDF markup tool (I used Preview on Mac), and then running the ZotFile tool to extract annotations from the PDF which creates a rich text (html) note for the item in Zotero. The notes are synced to the group library with Zotero online where they can be picked up for processing.\n",
        "\n",
        "For annotation, I used a combination of highlighting particular text and then tagging that text with a keyword corresponding to a target part of the citation metadata I'm trying to identify (e.g., title, authors, etc.). I should then be able to pull these two pieces out of the generated markdown into a data structure that I can feed back into the corresponding record via the Zotero API.\n",
        "\n",
        "For the Python processing workflow part of this, I used the pyzotero package to connect to the Zotero group library, read items with notes, and then processed those items to generate structured data from the HTML notes that can be reinjected back into the items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ump_4YY_PwtX",
        "outputId": "e8b72a38-e781-427d-81f0-a141c4bf88b6"
      },
      "source": [
        "!pip install pyzotero"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyzotero\n",
            "  Downloading Pyzotero-1.4.24-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from pyzotero) (2018.9)\n",
            "Collecting feedparser<6,>5.1.0\n",
            "  Downloading feedparser-5.2.1.zip (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 11.8 MB/s \n",
            "\u001b[?25hCollecting bibtexparser\n",
            "  Downloading bibtexparser-1.2.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from pyzotero) (1.0.1)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from pyzotero) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->pyzotero) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->pyzotero) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->pyzotero) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->pyzotero) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from bibtexparser->pyzotero) (2.4.7)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from bibtexparser->pyzotero) (0.16.0)\n",
            "Building wheels for collected packages: feedparser, bibtexparser\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-py3-none-any.whl size=44954 sha256=a18ec5bcd475f3a71480dfa5b5ee1613d1e3f0389d5cbc595ea5a94159a82326\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/bf/46/b4a597d435d3aee6c2fa583824897336d65abf13ebe3405b70\n",
            "  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bibtexparser: filename=bibtexparser-1.2.0-py3-none-any.whl size=36711 sha256=81e1543e8290c47b8306768f04e4d15af8d30b88c1134b437a81c98c79a547bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/13/1d/09c37a40f39ddd7b226719a797f1896a5b95d730de27e7a505\n",
            "Successfully built feedparser bibtexparser\n",
            "Installing collected packages: feedparser, bibtexparser, pyzotero\n",
            "Successfully installed bibtexparser-1.2.0 feedparser-5.2.1 pyzotero-1.4.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tah2x2bj9UWH"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from pyzotero import zotero\n",
        "from getpass import getpass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NDeZC__aA8Q"
      },
      "source": [
        "This function handles the process of working a given Zotero child item's note content to detect if it was generated using the ZotFile process and then extracting the annotations into a usable data structure (list of dictionaries)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vULdcZcWA-5V"
      },
      "source": [
        "annotation_property_map = [\n",
        "    {\n",
        "        \"property_name\": \"title\",\n",
        "        \"property_type\": \"single\"\n",
        "    },\n",
        "    {\n",
        "        \"property_name\": \"date\",\n",
        "        \"property_type\": \"single\"\n",
        "    },\n",
        "    {\n",
        "        \"property_name\": \"institution\",\n",
        "        \"property_type\": \"single\"\n",
        "    },\n",
        "    {\n",
        "        \"property_name\": \"author\",\n",
        "        \"property_type\": \"multi\"\n",
        "    },\n",
        "    {\n",
        "        \"property_name\": \"project\",\n",
        "        \"property_type\": \"tag\"\n",
        "    },\n",
        "    {\n",
        "        \"property_name\": \"place\",\n",
        "        \"property_type\": \"tag\"\n",
        "    },\n",
        "    {\n",
        "        \"property_name\": \"commodity\",\n",
        "        \"property_type\": \"tag\"\n",
        "    },\n",
        "]\n",
        "\n",
        "def structured_annotations(item_key, annotation_html, property_map=annotation_property_map):\n",
        "    extract_keywords = [i[\"property_name\"] for i in property_map]\n",
        "\n",
        "    annotations_soup = BeautifulSoup(annotation_html, 'html.parser')\n",
        "    pattern = '\\\"(.*?)\\\"'\n",
        "\n",
        "    paragraphs = annotations_soup.find_all(\"p\")\n",
        "\n",
        "    if \"Extracted Annotations\" not in paragraphs[0].text:\n",
        "        return None\n",
        "\n",
        "    annotation_texts = list()\n",
        "    for index,p in enumerate(paragraphs):\n",
        "        em_in_p = p.find(\"em\")\n",
        "        if em_in_p:\n",
        "            p_text = em_in_p.text\n",
        "        else:\n",
        "            p_text = p.text\n",
        "\n",
        "        p_text_parts = p_text.split()\n",
        "\n",
        "        if len(p_text_parts) > 0 and p_text_parts[0] in extract_keywords:\n",
        "            prop = p_text_parts[0]\n",
        "            annotation_text = re.search(pattern, paragraphs[index - 1].text)\n",
        "            if annotation_text is not None:\n",
        "                annotation_texts.append({\n",
        "                    \"item_key\": item_key,\n",
        "                    \"text\": annotation_text.group(1),\n",
        "                    \"property\": prop\n",
        "                })\n",
        "    return annotation_texts\n",
        "\n",
        "def update_zotero_item(\n",
        "    item_key, \n",
        "    annotations_list, \n",
        "    zotero_api, \n",
        "    commit_update=True,\n",
        "    property_map=annotation_property_map):\n",
        "    update_item = zotero_api.item(item_key)\n",
        "    if not update_item:\n",
        "        return\n",
        "\n",
        "    available_updates = [i for i in annotations_list if i[\"item_key\"] == item_key]\n",
        "    if available_updates:\n",
        "        single_value_props = [i[\"property_name\"] for i in property_map if i[\"property_type\"] == \"single\"]\n",
        "        tag_props = [i[\"property_name\"] for i in property_map if i[\"property_type\"] == \"tag\"]\n",
        "\n",
        "        for prop in single_value_props:\n",
        "            update_value = next((i[\"text\"] for i in available_updates if i[\"property\"] == prop), None)\n",
        "            if update_value is not None:\n",
        "                update_item[\"data\"][prop] = update_value\n",
        "\n",
        "        update_item[\"data\"][\"place\"] = \",\".join([i[\"text\"] for i in available_updates if i[\"property\"] == \"place\"])\n",
        "        update_item[\"data\"][\"creators\"] = [{'creatorType': 'author', 'name': i[\"text\"]} for i in available_updates if i[\"property\"] == \"author\"]\n",
        "        update_item[\"data\"][\"tags\"] = [{'tag': i[\"text\"]} for i in available_updates if i[\"property\"] in tag_props]\n",
        "\n",
        "    if commit_update:\n",
        "        zotero_api.update_item(update_item)\n",
        "\n",
        "    return update_item\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLX1_JRaaSCz"
      },
      "source": [
        "To interface with the Zotero API, you need to provide a library ID and an API key. This should work for anyone with a group library that has followed the same process I outlined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHy-0rgMP2HT",
        "outputId": "65e32831-f1d9-4599-aa7e-10d0e583ebc0"
      },
      "source": [
        "zot = zotero.Zotero(input(\"Library ID \"), \"group\", getpass(prompt=\"API Key \"))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Library ID 4373054\n",
            "API Key ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sK-iahFadzi"
      },
      "source": [
        "This process would need to be worked out further in production practice, but we essentially walk the items in a given library looking for notes. There might be some more efficient way to zero in on these, but I haven't figured it out yet with pyzotero. Here, we make a pass through every item, look for items with children, get the children, and then get any that have notes. I assume that this might be additive where all note items that can be processed will be yielding annotations for the given parent item. I send the note html along with the associated item key to the function to return available structured annotations for further processing. Since every annotation will essentially contain a key/value pair (property and text content), we can simply build out an array of these with their item keys for further processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5SPrL0oX-Fa"
      },
      "source": [
        "item_annotations = list()\n",
        "for item in zot.all_top():\n",
        "    if item[\"meta\"][\"numChildren\"] > 0:\n",
        "        note_children = [i for i in zot.children(item[\"key\"]) if i[\"data\"][\"itemType\"] == \"note\"]\n",
        "        if note_children:\n",
        "            for note_child in note_children:\n",
        "                extracted_annotations = structured_annotations(item[\"key\"], note_child[\"data\"][\"note\"])\n",
        "                if extracted_annotations:\n",
        "                    item_annotations.extend(extracted_annotations)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJB3IitmbQAd"
      },
      "source": [
        "In this case, we got the one item where I've annotated and then extracted text snippets corresponding to specific metadata elements I'm identifying and wanting to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvMrVsZJZ5D4",
        "outputId": "7e12e9ca-c715-41e8-e849-29515127c3a7"
      },
      "source": [
        "item_annotations"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'item_key': 'Z7B9EW8E',\n",
              "  'property': 'title',\n",
              "  'text': 'Technical Report on the Andrade Deposit, State of Rio Grande do Sul, Brazil'},\n",
              " {'item_key': 'Z7B9EW8E',\n",
              "  'property': 'institution',\n",
              "  'text': 'Aquia Resources Limited'},\n",
              " {'item_key': 'Z7B9EW8E', 'property': 'author', 'text': 'John Makin'},\n",
              " {'item_key': 'Z7B9EW8E', 'property': 'author', 'text': 'Chester M. Moore'},\n",
              " {'item_key': 'Z7B9EW8E', 'property': 'author', 'text': 'David Ross'},\n",
              " {'item_key': 'Z7B9EW8E', 'property': 'author', 'text': 'Luke Evans'},\n",
              " {'item_key': 'Z7B9EW8E',\n",
              "  'property': 'institution',\n",
              "  'text': 'Roscoe Postle Associates Inc. (RPA)'},\n",
              " {'item_key': 'Z7B9EW8E',\n",
              "  'property': 'place',\n",
              "  'text': 'State of Rio Grande do Sul, Brazil'},\n",
              " {'item_key': 'Z7B9EW8E', 'property': 'date', 'text': 'March 13, 2019'},\n",
              " {'item_key': 'Z7B9EW8E',\n",
              "  'property': 'project',\n",
              "  'text': 'Andrade copper deposit'},\n",
              " {'item_key': 'Z7B9EW8E', 'property': 'commodity', 'text': 'copper'},\n",
              " {'item_key': 'Z7B9EW8E', 'property': 'commodity', 'text': '-silver'},\n",
              " {'item_key': 'CXT2N7IH',\n",
              "  'property': 'title',\n",
              "  'text': 'NI 43-101 Technical Report Cerro Blanco Property San Juan Province, Argentina'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'author', 'text': 'Ryan McEachern'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'date', 'text': 'February 12, 2019'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'institution', 'text': 'STRATIS'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'place', 'text': 'Calingasta Valley.'},\n",
              " {'item_key': 'CXT2N7IH',\n",
              "  'property': 'project',\n",
              "  'text': 'Cerro Blanco property'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'place', 'text': 'San Juan Province'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'place', 'text': 'Frontal Cordillera'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'place', 'text': 'Argentina'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'commodity', 'text': 'copper'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'commodity', 'text': 'molybdenum'},\n",
              " {'item_key': 'CXT2N7IH', 'property': 'commodity', 'text': 'gold'},\n",
              " {'item_key': 'VLY39BAV',\n",
              "  'property': 'title',\n",
              "  'text': 'NI 43-101 Technical Report Bowdens Silver Project NSW, Australia'},\n",
              " {'item_key': 'VLY39BAV', 'property': 'date', 'text': '20 March 2020'},\n",
              " {'item_key': 'VLY39BAV',\n",
              "  'property': 'institution',\n",
              "  'text': 'Kangari Consulting Limited'},\n",
              " {'item_key': 'VLY39BAV', 'property': 'author', 'text': 'Timothy J. Strong'},\n",
              " {'item_key': 'VLY39BAV', 'property': 'place', 'text': 'New South Wales'},\n",
              " {'item_key': 'VLY39BAV', 'property': 'place', 'text': 'Australia'},\n",
              " {'item_key': 'VLY39BAV',\n",
              "  'property': 'project',\n",
              "  'text': 'Bowdens Silver Project'},\n",
              " {'item_key': 'VLY39BAV',\n",
              "  'property': 'place',\n",
              "  'text': 'Central Tablelands Region'},\n",
              " {'item_key': 'VLY39BAV', 'property': 'place', 'text': 'Mudgee'},\n",
              " {'item_key': 'VLY39BAV', 'property': 'commodity', 'text': 'silver'},\n",
              " {'item_key': 'QZFHM2ZK',\n",
              "  'property': 'institution',\n",
              "  'text': 'Avino Silver & Gold Mines Ltd.'},\n",
              " {'item_key': 'QZFHM2ZK',\n",
              "  'property': 'title',\n",
              "  'text': 'Resource Estimate Update for the Avino Property, Durango, Mexico'},\n",
              " {'item_key': 'QZFHM2ZK', 'property': 'date', 'text': 'JANUARY 13, 2021'},\n",
              " {'item_key': 'QZFHM2ZK', 'property': 'author', 'text': 'Hassan Ghaffari'},\n",
              " {'item_key': 'QZFHM2ZK', 'property': 'author', 'text': \"Michael F. O'Brien\"},\n",
              " {'item_key': 'QZFHM2ZK', 'property': 'author', 'text': 'Barnard Foo'},\n",
              " {'item_key': 'QZFHM2ZK',\n",
              "  'property': 'author',\n",
              "  'text': 'Jianhui (John) Huang'},\n",
              " {'item_key': 'QZFHM2ZK', 'property': 'place', 'text': 'San Gonzalo Mine'},\n",
              " {'item_key': 'QZFHM2ZK', 'property': 'place', 'text': 'Durango, Mexico'},\n",
              " {'item_key': 'QZFHM2ZK',\n",
              "  'property': 'place',\n",
              "  'text': 'Elena Tolosa (ET) Mine'},\n",
              " {'item_key': 'MFA5N9X9',\n",
              "  'property': 'institution',\n",
              "  'text': 'BULLFROG GOLD CORP.'},\n",
              " {'item_key': 'MFA5N9X9',\n",
              "  'property': 'title',\n",
              "  'text': 'NI 43-101 Technical Report Mineral Resource Estimate Bullfrog Gold Project Nye County, Nevada'},\n",
              " {'item_key': 'MFA5N9X9', 'property': 'date', 'text': 'August 9, 2017'},\n",
              " {'item_key': 'MFA5N9X9', 'property': 'author', 'text': 'Rex Bryan'},\n",
              " {'item_key': 'MFA5N9X9',\n",
              "  'property': 'project',\n",
              "  'text': 'Bullfrog Gold Project'},\n",
              " {'item_key': 'MFA5N9X9',\n",
              "  'property': 'place',\n",
              "  'text': 'Bullfrog Mining District'},\n",
              " {'item_key': 'MFA5N9X9', 'property': 'place', 'text': 'Bullfrog Hills'},\n",
              " {'item_key': 'MFA5N9X9', 'property': 'place', 'text': 'Nye County'},\n",
              " {'item_key': 'MFA5N9X9', 'property': 'place', 'text': 'Nevada'},\n",
              " {'item_key': 'MFA5N9X9', 'property': 'commodity', 'text': 'gold'},\n",
              " {'item_key': 'MFA5N9X9', 'property': 'commodity', 'text': 'silver'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY4e7qQYLdoC"
      },
      "source": [
        "I added an additional function to work through the annotations gathered and commit them back to the respective Zotero items cataloging the annotated files. This basically roundtrips the process, letting us propose a workflow concentrated on marking up \"messy\" PDF files using meta keywords and then leveraging Zotero and ZotFile to build out the catalog records from the annotation markup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuhPsN7b3HhM"
      },
      "source": [
        "for item_key in list(set([i[\"item_key\"] for i in item_annotations])):\n",
        "    update_zotero_item(item_key, item_annotations, zot, commit_update=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJFRZHCoH4oE"
      },
      "source": [
        "What I did above so far is a reasonable start, but there are a few issues.\n",
        "\n",
        "* This is pretty brittle at this point and requires a very specific convention to be followed in annotating a PDF text. This would need to be made a bit more robust in terms of dealing with text strings and different things people might do in free and open annotations. I mitigated this a little bit in the function by first looking for a set of keywords identifying the specific bits of annotation that we want to go after and then getting the highlighted text the annotation is identifying. However, some type of conventions would need to be established and followed in terms of highlighting a chunk of text and then marking up its particular significance. If we want to simply pick out the major elements of reasonably complete citation metadata, then something like I tried here should work well enough.\n",
        "* I still need to work out the best way to feed everything back into building more usable report reference items in Zotero once metadata properties are extracted. That should be pretty straightforward, but I want to fiddle with the simplest workflow possible where someone would mark up a bunch of PDFs quickly, load the files to the Zotero library without making report items from them, and then see if the whole process can work from there.\n",
        "\n",
        "My takeaway so far is that it's actually really nice and fast to simply open up a PDF file and start marking it up. Theoretically, this could be done on a whole batch of PDFs totally separate from Zotero, bulk import those to Zotero, run the ZotFile extraction on the annotations, and then generate properly documented items. For the types of files this applies to, Zotero is not going to recognize that they should be \"report\" type items, so that part of things would need to be handled through the API. As noted, the real point here is to train an AI to do this work, at least within some contextual boundaries. But even if it was a person sitting down doing this work, it should be much faster to open a PDF, mark it up following a particular convention to identify the important bits, and then have a system take over to parse and catalog the files."
      ]
    }
  ]
}